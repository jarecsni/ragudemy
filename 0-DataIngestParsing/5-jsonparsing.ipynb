{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99920b01",
   "metadata": {},
   "source": [
    "### JSON Parsing and Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd616fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/json_files2\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7605e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {\n",
    "  \"company\": \"TechCorp\",\n",
    "  \"employees\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"name\": \"John Doe\",\n",
    "      \"role\": \"Software Engineer\",\n",
    "      \"skills\": [\n",
    "        \"Python\",\n",
    "        \"JavaScript\",\n",
    "        \"React\"\n",
    "      ],\n",
    "      \"projects\": [\n",
    "        {\n",
    "          \"name\": \"RAG System\",\n",
    "          \"status\": \"In Progress\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"Data Pipeline\",\n",
    "          \"status\": \"Completed\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"id\": 2,\n",
    "      \"name\": \"Jane Smith\",\n",
    "      \"role\": \"Data Scientist\",\n",
    "      \"skills\": [\n",
    "        \"Python\",\n",
    "        \"Machine Learning\",\n",
    "        \"SQL\"\n",
    "      ],\n",
    "      \"projects\": [\n",
    "        {\n",
    "          \"name\": \"ML Model\",\n",
    "          \"status\": \"In Progress\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"Analytics Dashboard\",\n",
    "          \"status\": \"Planning\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"departments\": {\n",
    "    \"engineering\": {\n",
    "      \"head\": \"Mike Johnson\",\n",
    "      \"budget\": 1000000,\n",
    "      \"team_size\": 25\n",
    "    },\n",
    "    \"data_science\": {\n",
    "      \"head\": \"Sarah Williams\",\n",
    "      \"budget\": 750000,\n",
    "      \"team_size\": 15\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "with open(\"data/json_files2/company_data.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ae6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_data = [\n",
    "    {\"timestamp\": \"2024-01-01\", \"event\": \"user_login\", \"user_id\": 123},\n",
    "    {\"timestamp\": \"2024-01-01\", \"event\": \"page_view\",\"user_id\": 123, \"page\": \"/home\"},\n",
    "    {\"timestamp\": \"2024-01-01\", \"event\": \"purchase\", \"user_id\": 123, \"amount\": 99.99}\n",
    "]\n",
    "\n",
    "with open(\"data/json_files2/events.jsonl\", \"w\") as f:\n",
    "    for entry in jsonl_data:\n",
    "        f.write(json.dumps(entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e91a7",
   "metadata": {},
   "source": [
    "### JSON Processing Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8bcd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 employee documents\n",
      "First employee document: {\"id\": 1, \"name\": \"John Doe\", \"role\": \"Software Engineer\", \"skills\": [\"Python\", \"JavaScript\", \"React\"], \"projects\": [{\"name\": \"RAG System\", \"status\": \"In Progress\"}, {\"name\": \"Data Pipeline\", \"status\"\n",
      "[Document(metadata={'source': '/Users/johnny/dev/ai/ragudemy/0-DataIngestParsing/data/json_files2/company_data.json', 'seq_num': 1}, page_content='{\"id\": 1, \"name\": \"John Doe\", \"role\": \"Software Engineer\", \"skills\": [\"Python\", \"JavaScript\", \"React\"], \"projects\": [{\"name\": \"RAG System\", \"status\": \"In Progress\"}, {\"name\": \"Data Pipeline\", \"status\": \"Completed\"}]}'), Document(metadata={'source': '/Users/johnny/dev/ai/ragudemy/0-DataIngestParsing/data/json_files2/company_data.json', 'seq_num': 2}, page_content='{\"id\": 2, \"name\": \"Jane Smith\", \"role\": \"Data Scientist\", \"skills\": [\"Python\", \"Machine Learning\", \"SQL\"], \"projects\": [{\"name\": \"ML Model\", \"status\": \"In Progress\"}, {\"name\": \"Analytics Dashboard\", \"status\": \"Planning\"}]}')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "import json\n",
    "\n",
    "## Method1 - JSONLoader with jq_schema\n",
    "employee_loader = JSONLoader(\n",
    "    file_path=\"data/json_files2/company_data.json\",\n",
    "    jq_schema='.employees[]', # Extracts each employee as a separate document\n",
    "    text_content=False\n",
    ")\n",
    "employee_docs = employee_loader.load()\n",
    "print(f\"Loaded {len(employee_docs)} employee documents\")\n",
    "print(f\"First employee document: {employee_docs[0].page_content[:200]}\")\n",
    "print(employee_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef24c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2️⃣ Custom JSON processing\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "## Method2 - JSONLoader with custom function (for complex structures)\n",
    "print(\"2️⃣ Custom JSON processing\")\n",
    "def process_json_intelligently(filepath: str) -> list[Document]:\n",
    "    \"\"\"Process JSON with custom logic for complex structures\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    documents = []  \n",
    "    for emp in json_data.get('employees', []):\n",
    "        content = f\"\"\"Employee Information:\n",
    "        Name: {emp['name']}\n",
    "        Role: {emp['role']}\n",
    "        Skills: {', '.join(emp['skills'])}\n",
    "        Projects: \"\"\" \n",
    "        # Projects: {', '.join([p['name'] for p in emp['projects']])}\"\"\"\n",
    "        for project in emp.get('projects', []):\n",
    "            content += f\"\\n- {project['name']} ({project['status']})\"\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                'source': filepath,\n",
    "                'employee_id': emp['id'],\n",
    "                'employee_name': emp['name'],\n",
    "                'role': emp['role'],\n",
    "                'data_type': 'employee_info'\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    return documents\n",
    "\n",
    "process_json_intelligently(\"data/json_files2/company_data.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
