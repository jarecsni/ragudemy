{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e26be50",
   "metadata": {},
   "source": [
    "### Introduction to Data Ingestion and Parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31ae598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3bf816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up is complete!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "print(\"Set up is complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd97206",
   "metadata": {},
   "source": [
    "### Understanding the Document Structure in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1838d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document structure\n",
      "Content: This is the main text content that will be embedded and searched.\n",
      "Metadata: {'source': 'example.txt', 'page': 1, 'author': 'Johnny Boy', 'date_created': '2025-09-02', 'custom_field': 'custom_value'}\n"
     ]
    }
   ],
   "source": [
    "## Create a simple document\n",
    "doc = Document(\n",
    "    page_content=\"This is the main text content that will be embedded and searched.\",\n",
    "    metadata={\n",
    "        \"source\": \"example.txt\",\n",
    "        \"page\": 1,\n",
    "        \"author\": \"Johnny Boy\",\n",
    "        \"date_created\": \"2025-09-02\",\n",
    "        \"custom_field\": \"custom_value\",\n",
    "    },\n",
    ")\n",
    "print(\"Document structure\");\n",
    "print(f\"Content: {doc.page_content}\");\n",
    "print(f\"Metadata: {doc.metadata}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c9efb",
   "metadata": {},
   "source": [
    "### Text Files (.txt) - The simplest case {#2-text-files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4292be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple text file\n",
    "import os\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "295cb674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/text_files/python_intro.txt created\n",
      "data/text_files/machine_learning.txt created\n"
     ]
    }
   ],
   "source": [
    "sample_texts = {\n",
    "    \"data/text_files/python_intro.txt\": \"\"\"1-dataingestion.ipynb\n",
    "Python's dynamic typing allows flexible code but can cause runtime errors.\n",
    "The GIL prevents true multithreading, making multiprocessing better for CPU tasks.\n",
    "List comprehensions replace for loops with readable one-liners.\n",
    "Python emphasizes readability and the principle of one obvious way.\n",
    "The standard library is extensive, earning Python the 'batteries included' nickname.\n",
    "Duck typing determines suitability by methods, not actual type.\n",
    "Python's interpreter enables rapid prototyping and interactive development.\n",
    "Data science popularity comes from NumPy, Pandas, and Scikit-learn libraries.\n",
    "Python's natural language syntax makes it ideal for beginners.\n",
    "Virtual environments solve dependency conflicts between projects\n",
    "    \"\"\",\n",
    "    \"data/text_files/machine_learning.txt\": \"\"\"\n",
    "Machine learning algorithms learn patterns from data without explicit programming.\n",
    "Supervised learning uses labeled data to predict outcomes on new examples.\n",
    "Unsupervised learning finds hidden structures in data without target labels.\n",
    "Neural networks mimic brain neurons with interconnected layers of nodes.\n",
    "Deep learning uses multiple hidden layers to model complex relationships.\n",
    "Overfitting occurs when models memorize training data but fail on new data.\n",
    "Cross-validation splits data to test model performance on unseen examples.\n",
    "Feature engineering transforms raw data into meaningful model inputs.\n",
    "Gradient descent optimizes model parameters by minimizing prediction errors.\n",
    "Ensemble methods combine multiple models to improve overall accuracy.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "for filepath, content in sample_texts.items():\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    print(f\"{filepath} created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4521a7",
   "metadata": {},
   "source": [
    "### TextLoader - Read a Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45e5f9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n",
      "Content: 1-dataingestion.ipynb\n",
      "Python's dynamic typing allows flexible code but can cause runtime errors.\n",
      "The\n",
      "Metadata: {'source': 'data/text_files/python_intro.txt'}\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "##from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "print(f\"Content: {docs[0].page_content[:100]}\")\n",
    "print(f\"Metadata: {docs[0].metadata}\")\n",
    "print(type(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2717e2d5",
   "metadata": {},
   "source": [
    "### DirectoryLoader - Multiple Text Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065ce61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 3943.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2\n",
      "Document 1:\n",
      "   Source: data/text_files/python_intro.txt\n",
      "   Lenght: 747 characters\n",
      "Document 2:\n",
      "   Source: data/text_files/machine_learning.txt\n",
      "   Lenght: 755 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\n",
    "    \"data/text_files/\", \n",
    "    glob=\"**/*.txt\", \n",
    "    loader_cls=TextLoader,\n",
    "    show_progress=True\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"   Source: {doc.metadata['source']}\")\n",
    "    print(f\"   Lenght: {len(doc.page_content)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a17475",
   "metadata": {},
   "source": [
    "### Text Splitting Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "390789fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content=\"1-dataingestion.ipynb\\nPython's dynamic typing allows flexible code but can cause runtime errors.\\nThe GIL prevents true multithreading, making multiprocessing better for CPU tasks.\\nList comprehensions replace for loops with readable one-liners.\\nPython emphasizes readability and the principle of one obvious way.\\nThe standard library is extensive, earning Python the 'batteries included' nickname.\\nDuck typing determines suitability by methods, not actual type.\\nPython's interpreter enables rapid prototyping and interactive development.\\nData science popularity comes from NumPy, Pandas, and Scikit-learn libraries.\\nPython's natural language syntax makes it ideal for beginners.\\nVirtual environments solve dependency conflicts between projects\\n    \"), Document(metadata={'source': 'data/text_files/machine_learning.txt'}, page_content='\\nMachine learning algorithms learn patterns from data without explicit programming.\\nSupervised learning uses labeled data to predict outcomes on new examples.\\nUnsupervised learning finds hidden structures in data without target labels.\\nNeural networks mimic brain neurons with interconnected layers of nodes.\\nDeep learning uses multiple hidden layers to model complex relationships.\\nOverfitting occurs when models memorize training data but fail on new data.\\nCross-validation splits data to test model performance on unseen examples.\\nFeature engineering transforms raw data into meaningful model inputs.\\nGradient descent optimizes model parameters by minimizing prediction errors.\\nEnsemble methods combine multiple models to improve overall accuracy.\\n    ')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "print(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27fac41",
   "metadata": {},
   "source": [
    "### Method 1 - Character Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e4c692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharacterTextSplitter\n",
      "Number of chunks: 10\n",
      "Chunk 1: 1-dataingestion.ipynb\n",
      "Python's dynamic typing allows flexible code but can cause runtime errors.\n",
      "\n",
      "Chunk 2: The GIL prevents true multithreading, making multiprocessing better for CPU tasks.\n",
      "\n",
      "Chunk 3: List comprehensions replace for loops with readable one-liners.\n",
      "\n",
      "Chunk 4: Python emphasizes readability and the principle of one obvious way.\n",
      "\n",
      "Chunk 5: The standard library is extensive, earning Python the 'batteries included' nickname.\n",
      "\n",
      "Chunk 6: Duck typing determines suitability by methods, not actual type.\n",
      "\n",
      "Chunk 7: Python's interpreter enables rapid prototyping and interactive development.\n",
      "\n",
      "Chunk 8: Data science popularity comes from NumPy, Pandas, and Scikit-learn libraries.\n",
      "\n",
      "Chunk 9: Python's natural language syntax makes it ideal for beginners.\n",
      "\n",
      "Chunk 10: Virtual environments solve dependency conflicts between projects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text=docs[0].page_content\n",
    "print(\"CharacterTextSplitter\")\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", # Split on newlines prevents overlaps, use \" \" to see overlaps\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    ")\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "print(f\"Number of chunks: {len(char_chunks)}\")\n",
    "for i, chunk in enumerate(char_chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eed574e",
   "metadata": {},
   "source": [
    "### Method 2 - RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RecursiveCharacterTextSplitter\")\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "chunks = recursive_splitter.split_text(text)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a035c",
   "metadata": {},
   "source": [
    "### Method 3 - Token Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3bffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TokenTextSplitter\")\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    ")\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f\"created {len(token_chunks)} chunks\")\n",
    "print(f\"first chunk: {token_chunks[0][:100]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
