{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e26be50",
   "metadata": {},
   "source": [
    "### Introduction to Data Ingestion and Parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ae598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3bf816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "print(\"Set up is complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd97206",
   "metadata": {},
   "source": [
    "### Understanding the Document Structure in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1838d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple document\n",
    "doc = Document(\n",
    "    page_content=\"This is the main text content that will be embedded and searched.\",\n",
    "    metadata={\n",
    "        \"source\": \"example.txt\",\n",
    "        \"page\": 1,\n",
    "        \"author\": \"Johnny Boy\",\n",
    "        \"date_created\": \"2025-09-02\",\n",
    "        \"custom_field\": \"custom_value\",\n",
    "    },\n",
    ")\n",
    "print(\"Document structure\");\n",
    "print(f\"Content: {doc.page_content}\");\n",
    "print(f\"Metadata: {doc.metadata}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c9efb",
   "metadata": {},
   "source": [
    "### Text Files (.txt) - The simplest case {#2-text-files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4292be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a simple text file\n",
    "import os\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295cb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = {\n",
    "    \"data/text_files/python_intro.txt\": \"\"\"1-dataingestion.ipynb\n",
    "Python's dynamic typing allows flexible code but can cause runtime errors.\n",
    "The GIL prevents true multithreading, making multiprocessing better for CPU tasks.\n",
    "List comprehensions replace for loops with readable one-liners.\n",
    "Python emphasizes readability and the principle of one obvious way.\n",
    "The standard library is extensive, earning Python the 'batteries included' nickname.\n",
    "Duck typing determines suitability by methods, not actual type.\n",
    "Python's interpreter enables rapid prototyping and interactive development.\n",
    "Data science popularity comes from NumPy, Pandas, and Scikit-learn libraries.\n",
    "Python's natural language syntax makes it ideal for beginners.\n",
    "Virtual environments solve dependency conflicts between projects\n",
    "    \"\"\",\n",
    "    \"data/text_files/machine_learning.txt\": \"\"\"\n",
    "Machine learning algorithms learn patterns from data without explicit programming.\n",
    "Supervised learning uses labeled data to predict outcomes on new examples.\n",
    "Unsupervised learning finds hidden structures in data without target labels.\n",
    "Neural networks mimic brain neurons with interconnected layers of nodes.\n",
    "Deep learning uses multiple hidden layers to model complex relationships.\n",
    "Overfitting occurs when models memorize training data but fail on new data.\n",
    "Cross-validation splits data to test model performance on unseen examples.\n",
    "Feature engineering transforms raw data into meaningful model inputs.\n",
    "Gradient descent optimizes model parameters by minimizing prediction errors.\n",
    "Ensemble methods combine multiple models to improve overall accuracy.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "for filepath, content in sample_texts.items():\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    print(f\"{filepath} created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4521a7",
   "metadata": {},
   "source": [
    "### TextLoader - Read a Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e5f9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n",
      "Content: 1-dataingestion.ipynb\n",
      "Python's dynamic typing allows flexible code but can cause runtime errors.\n",
      "The\n",
      "Metadata: {'source': 'data/text_files/python_intro.txt'}\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "##from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "print(f\"Content: {docs[0].page_content[:100]}\")\n",
    "print(f\"Metadata: {docs[0].metadata}\")\n",
    "print(type(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2717e2d5",
   "metadata": {},
   "source": [
    "### DirectoryLoader - Multiple Text Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "065ce61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1900.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2\n",
      "Document 1:\n",
      "   Source: data/text_files/python_intro.txt\n",
      "   Lenght: 747 characters\n",
      "Document 2:\n",
      "   Source: data/text_files/machine_learning.txt\n",
      "   Lenght: 755 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\n",
    "    \"data/text_files/\", \n",
    "    glob=\"**/*.txt\", \n",
    "    loader_cls=TextLoader,\n",
    "    show_progress=True\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"   Source: {doc.metadata['source']}\")\n",
    "    print(f\"   Lenght: {len(doc.page_content)} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a17475",
   "metadata": {},
   "source": [
    "### Text Splitting Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390789fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content=\"1-dataingestion.ipynb\\nPython's dynamic typing allows flexible code but can cause runtime errors.\\nThe GIL prevents true multithreading, making multiprocessing better for CPU tasks.\\nList comprehensions replace for loops with readable one-liners.\\nPython emphasizes readability and the principle of one obvious way.\\nThe standard library is extensive, earning Python the 'batteries included' nickname.\\nDuck typing determines suitability by methods, not actual type.\\nPython's interpreter enables rapid prototyping and interactive development.\\nData science popularity comes from NumPy, Pandas, and Scikit-learn libraries.\\nPython's natural language syntax makes it ideal for beginners.\\nVirtual environments solve dependency conflicts between projects\\n    \"), Document(metadata={'source': 'data/text_files/machine_learning.txt'}, page_content='\\nMachine learning algorithms learn patterns from data without explicit programming.\\nSupervised learning uses labeled data to predict outcomes on new examples.\\nUnsupervised learning finds hidden structures in data without target labels.\\nNeural networks mimic brain neurons with interconnected layers of nodes.\\nDeep learning uses multiple hidden layers to model complex relationships.\\nOverfitting occurs when models memorize training data but fail on new data.\\nCross-validation splits data to test model performance on unseen examples.\\nFeature engineering transforms raw data into meaningful model inputs.\\nGradient descent optimizes model parameters by minimizing prediction errors.\\nEnsemble methods combine multiple models to improve overall accuracy.\\n    ')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "print(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27fac41",
   "metadata": {},
   "source": [
    "### Method 1 - Character Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=docs[0].page_content\n",
    "print(\"CharacterTextSplitter\")\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", # Split on newlines prevents overlaps, use \" \" to see overlaps\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    ")\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "print(f\"Number of chunks: {len(char_chunks)}\")\n",
    "for i, chunk in enumerate(char_chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eed574e",
   "metadata": {},
   "source": [
    "### Method 2 - RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21c767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveCharacterTextSplitter\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextSplitter.__init__() got an unexpected keyword argument 'separetors'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRecursiveCharacterTextSplitter\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m recursive_splitter = \u001b[43mRecursiveCharacterTextSplitter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_overlap\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlength_function\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparetors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m recursive_chunks = recursive_splitter.split_text(text)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of chunks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(recursive_chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ai/ragudemy/.venv/lib/python3.13/site-packages/langchain_text_splitters/character.py:94\u001b[39m, in \u001b[36mRecursiveCharacterTextSplitter.__init__\u001b[39m\u001b[34m(self, separators, keep_separator, is_separator_regex, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     87\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     88\u001b[39m     separators: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m     **kwargs: Any,\n\u001b[32m     92\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     93\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Create a new TextSplitter.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeep_separator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_separator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28mself\u001b[39m._separators = separators \u001b[38;5;129;01mor\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_separator_regex = is_separator_regex\n",
      "\u001b[31mTypeError\u001b[39m: TextSplitter.__init__() got an unexpected keyword argument 'separetors'"
     ]
    }
   ],
   "source": [
    "print(\"RecursiveCharacterTextSplitter\")\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "print(f\"Number of chunks: {len(recursive_chunks)}\")\n",
    "for i, chunk in enumerate(recursive_chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk}\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
